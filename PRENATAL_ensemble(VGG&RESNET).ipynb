{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dV4Ju64rydle",
        "outputId": "05d72e1b-a1b1-43df-bfc8-5bd8a972c159"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Parameters\n",
        "batch_size = 16\n",
        "img_height = 224\n",
        "img_width = 224\n",
        "data_dir = '/content/drive/MyDrive/prenatal'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import VGG19, ResNet50, DenseNet121, MobileNetV2\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "\n",
        "# Load and prepare dataset (as previously done)\n",
        "batch_size = 16\n",
        "img_height = 224\n",
        "img_width = 224\n",
        "data_dir = '/content/drive/MyDrive/prenatal'\n",
        "\n",
        "dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    seed=123\n",
        ")\n",
        "class_names = dataset.class_names\n",
        "print(f\"Class names: {class_names}\")\n",
        "\n",
        "# Split dataset into train, val, test\n",
        "train_size = 0.8\n",
        "val_size = 0.1\n",
        "test_size = 0.1\n",
        "\n",
        "total_count = len(dataset)\n",
        "train_count = int(total_count * train_size)\n",
        "val_count = int(total_count * val_size)\n",
        "\n",
        "train_ds = dataset.take(train_count)\n",
        "val_ds = dataset.skip(train_count).take(val_count)\n",
        "test_ds = dataset.skip(train_count + val_count)\n",
        "\n",
        "# Data Augmentation\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "    layers.RandomRotation(0.2),\n",
        "    layers.RandomZoom(0.2),\n",
        "    layers.RandomContrast(0.1),\n",
        "])\n",
        "\n",
        "train_ds = train_ds.map(lambda x, y: (data_augmentation(x), y))\n",
        "train_ds = train_ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "test_ds = test_ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "# Function to create a model\n",
        "def create_model(base_model, input_shape, num_classes, freeze=True):\n",
        "    base_model.trainable = not freeze\n",
        "    model = models.Sequential([\n",
        "        base_model,\n",
        "        layers.GlobalAveragePooling2D(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create individual models\n",
        "vgg19_base = VGG19(input_shape=(img_height, img_width, 3), include_top=False, weights='imagenet')\n",
        "resnet50_base = ResNet50(input_shape=(img_height, img_width, 3), include_top=False, weights='imagenet')\n",
        "\n",
        "\n",
        "vgg19_model = create_model(vgg19_base, (img_height, img_width, 3), len(class_names))\n",
        "resnet50_model = create_model(resnet50_base, (img_height, img_width, 3), len(class_names))\n",
        "\n",
        "# Train individual models\n",
        "epochs = 10\n",
        "vgg19_history = vgg19_model.fit(train_ds, validation_data=val_ds, epochs=epochs)\n",
        "resnet50_history = resnet50_model.fit(train_ds, validation_data=val_ds, epochs=epochs)\n",
        "\n",
        "\n",
        "# Evaluate models\n",
        "vgg19_acc = vgg19_model.evaluate(test_ds)[1]\n",
        "resnet50_acc = resnet50_model.evaluate(test_ds)[1]\n",
        "\n",
        "print(f\"VGG19 Test Accuracy: {vgg19_acc:.2f}\")\n",
        "print(f\"ResNet50 Test Accuracy: {resnet50_acc:.2f}\")\n",
        "\n",
        "# Combine predictions (Ensemble)\n",
        "def ensemble_predictions(models, test_ds):\n",
        "    all_preds = []\n",
        "    all_true = []\n",
        "\n",
        "    for images, labels in test_ds:\n",
        "        all_true.extend(labels.numpy())\n",
        "        model_preds = np.zeros((images.shape[0], len(class_names)))\n",
        "\n",
        "        # Collect predictions from each model\n",
        "        for model in models:\n",
        "            preds = model.predict(images)\n",
        "            model_preds += preds  # Sum the probabilities\n",
        "\n",
        "        # Average the predictions (for soft-voting)\n",
        "        avg_preds = model_preds / len(models)\n",
        "        all_preds.extend(np.argmax(avg_preds, axis=1))\n",
        "\n",
        "    return np.array(all_true), np.array(all_preds)\n",
        "\n",
        "# Ensemble models\n",
        "models = [vgg19_model, resnet50_model, ]\n",
        "y_true, y_pred = ensemble_predictions(models, test_ds)\n",
        "\n",
        "# Classification report\n",
        "print(\"\\nEnsemble Classification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=class_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Bl-OMGVzGPt",
        "outputId": "97913934-ad75-45a2-db80-94020fdfd984"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1684 files belonging to 2 classes.\n",
            "Class names: ['Non-standard', 'Standard']\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m80134624/80134624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n",
            "Epoch 1/10\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 3s/step - accuracy: 0.6971 - loss: 1.4835 - val_accuracy: 0.8562 - val_loss: 0.3676\n",
            "Epoch 2/10\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 660ms/step - accuracy: 0.7998 - loss: 0.4912 - val_accuracy: 0.8062 - val_loss: 0.4773\n",
            "Epoch 3/10\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 604ms/step - accuracy: 0.8189 - loss: 0.4132 - val_accuracy: 0.8375 - val_loss: 0.3703\n",
            "Epoch 4/10\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 585ms/step - accuracy: 0.8392 - loss: 0.3733 - val_accuracy: 0.8500 - val_loss: 0.3797\n",
            "Epoch 5/10\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 635ms/step - accuracy: 0.8475 - loss: 0.3551 - val_accuracy: 0.8250 - val_loss: 0.4329\n",
            "Epoch 6/10\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 568ms/step - accuracy: 0.8690 - loss: 0.3388 - val_accuracy: 0.8375 - val_loss: 0.3411\n",
            "Epoch 7/10\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 627ms/step - accuracy: 0.8519 - loss: 0.3487 - val_accuracy: 0.8813 - val_loss: 0.3013\n",
            "Epoch 8/10\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 570ms/step - accuracy: 0.8680 - loss: 0.3294 - val_accuracy: 0.8500 - val_loss: 0.3520\n",
            "Epoch 9/10\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 634ms/step - accuracy: 0.8647 - loss: 0.3074 - val_accuracy: 0.8625 - val_loss: 0.3408\n",
            "Epoch 10/10\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 621ms/step - accuracy: 0.8590 - loss: 0.3262 - val_accuracy: 0.8625 - val_loss: 0.3532\n",
            "Epoch 1/10\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 606ms/step - accuracy: 0.7396 - loss: 0.7610 - val_accuracy: 0.8125 - val_loss: 0.4637\n",
            "Epoch 2/10\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 565ms/step - accuracy: 0.8340 - loss: 0.3665 - val_accuracy: 0.8500 - val_loss: 0.2710\n",
            "Epoch 3/10\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 550ms/step - accuracy: 0.8415 - loss: 0.3421 - val_accuracy: 0.8562 - val_loss: 0.3359\n",
            "Epoch 4/10\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 625ms/step - accuracy: 0.8621 - loss: 0.3160 - val_accuracy: 0.8813 - val_loss: 0.2913\n",
            "Epoch 5/10\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 621ms/step - accuracy: 0.8665 - loss: 0.3122 - val_accuracy: 0.8062 - val_loss: 0.4391\n",
            "Epoch 6/10\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 621ms/step - accuracy: 0.8841 - loss: 0.3024 - val_accuracy: 0.8875 - val_loss: 0.3070\n",
            "Epoch 7/10\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 557ms/step - accuracy: 0.8860 - loss: 0.2873 - val_accuracy: 0.8750 - val_loss: 0.3388\n",
            "Epoch 8/10\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 553ms/step - accuracy: 0.8880 - loss: 0.2768 - val_accuracy: 0.9250 - val_loss: 0.2329\n",
            "Epoch 9/10\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 550ms/step - accuracy: 0.8896 - loss: 0.2810 - val_accuracy: 0.9062 - val_loss: 0.2243\n",
            "Epoch 10/10\n",
            "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 610ms/step - accuracy: 0.8942 - loss: 0.2634 - val_accuracy: 0.8562 - val_loss: 0.2979\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 851ms/step - accuracy: 0.8594 - loss: 0.3727\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 456ms/step - accuracy: 0.8615 - loss: 0.2927\n",
            "VGG19 Test Accuracy: 0.87\n",
            "ResNet50 Test Accuracy: 0.87\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 578ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
            "\n",
            "Ensemble Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "Non-standard       0.73      0.94      0.82        51\n",
            "    Standard       0.97      0.86      0.91       129\n",
            "\n",
            "    accuracy                           0.88       180\n",
            "   macro avg       0.85      0.90      0.87       180\n",
            "weighted avg       0.90      0.88      0.89       180\n",
            "\n"
          ]
        }
      ]
    }
  ]
}